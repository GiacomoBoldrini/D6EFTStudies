# HT condor test job
# ------------------
#
# tutorial: http://batchdocs.web.cern.ch/batchdocs/local/index.html
# how to run: condor_submit job.sub 
# how to monitor: condor_q

executable            = job.sh
# must be executable, i.e. chmod 755

process_name          = SSeu_RcW
madgraph_folder       = /afs/cern.ch/user/g/govoni/work/2019_VBS/generation/$(process_name)
results_folder        = /afs/cern.ch/user/g/govoni/work/2019_VBS/generation/SSeu_RcW_results_0p3_HS 
events_folder         = $(process_name)_$(ProcId)
cmssw_folder          = /afs/cern.ch/user/g/govoni/work/2019_VBS/CMSSW_10_6_0/src
events_number         = 10000

arguments             = $(ClusterId) $(ProcId) $(process_name) $(events_folder) $(madgraph_folder) $(results_folder) $(cmssw_folder) $(events_number)
# ClusterId = the submitted job
# ProcId = subjobs in which the cluster may be divided

# input  = jobinput.txt

output                = $(results_folder)/job.$(ClusterId).$(ProcId).out
error                 = $(results_folder)/job.$(ClusterId).$(ProcId).err
log                   = $(results_folder)/job.$(ClusterId).log
# NB condor does not create folders!

+JobFlavour = "workday"
# NB it's real time
# espresso     = 20 minutes (default)
# microcentury = 1 hour
# longlunch    = 2 hours
# workday      = 8 hours
# tomorrow     = 1 day
# testmatch    = 3 days
# nextweek     = 1 week
# Setting manually can be achieved by placing the following in your submit file:
# MaxRuntime = Number of seconds

queue 100
# The queue directive can take an integer to submit multiple jobs,
# each job will have an incremental $ProcId
# Note that the queue command has many other features, 
# relevant for several job submission in a single cluster of jobs


# if I wanted to run the job again, with changed arguments:
# https://research.cs.wisc.edu/htcondor/tutorials/fermi-2005/submit_first.html
# arguments = 4 11
# queue
# arguments = 4 12
# queue

